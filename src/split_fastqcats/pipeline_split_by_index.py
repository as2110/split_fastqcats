"""===========================
Pipeline split by index
===========================

Overview
========

The aim of this pipeline is to take a nanopore input fastq and then process
the file so that it splits the files out into individual fastq files based
on the barcode sequences. It will demultiplex and split concatenated reads in a single pipeline.

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.yml` file.
CGATReport report requires a :file:`conf.py` and optionally a
:file:`cgatreport.ini` file (see :ref:`PipelineReporting`).

Default configuration files can be generated by executing:
CHANGE THIS
   python <srcdir>/pipeline_barcode.py config

Input files
-----------

fastq.gz file of nanopore reads that have been sequenced with trimer barcodes
at the polyA end.

Pipeline output
===============

Individual fastq files split based on the presence of the barcode 

Code
====

"""
import sys
import os
import glob
import pandas as pd
from ruffus import *
import cgatcore.pipeline as P
import cgatcore.experiment as E

# Load parameters from the config file
PARAMS = P.get_parameters([
    "%s/pipeline.yml" % os.path.splitext(__file__)[0],
    "../pipeline.yml",
    "pipeline.yml"])

# Get the list of indexes from the YAML config file
INDEXES = PARAMS.get('indexes', [])

SEQUENCESUFFIXES = ("*.fastq.gz")
FASTQTARGET = tuple([os.path.join("data.dir/", suffix_name)
                     for suffix_name in SEQUENCESUFFIXES])
                     
PYTHON_ROOT = os.path.join(os.path.dirname(__file__), "python/")
BASH_ROOT = os.path.join(os.path.dirname(__file__), "bash/")

@follows(mkdir("split_tmp.dir"))
@transform('data.dir/*.fastq.gz',
           regex('data.dir/(\S+).fastq.gz'),
           r"split_tmp.dir/\1.aa.fastq.gz")
def split_fastq(infile, outfile):
    '''
    Split the fastq file into smaller chunks.
    '''
    infile = "".join(infile)
    name = infile.replace('data.dir/','').replace('.fastq.gz','')
    statement = '''zcat %(infile)s | split -l %(split)s -d --additional-suffix=.fastq.gz %(name)s. &&
                   mv %(name)s* split_tmp.dir/'''
    P.run(statement)

@follows(split_fastq)
@follows(mkdir("separate_samples.dir"))
@transform('split_tmp.dir/*.fastq.gz',
           regex("split_tmp.dir/(\S+).fastq.gz"),
           r"separate_samples.dir/\1")
def separate_by_index(infile, outfile):
    '''
    Identify barcode and split reads accordingly using a different script.
    '''
    name = os.path.basename(infile).replace('.fastq.gz', '')
    results_dir = os.path.join("separate_samples.dir", name)
    statement = '''mkdir -p %(results_dir)s &&
                   python %(PYTHON_ROOT)s/fastq_splitter_index_fuzzy.py -e 3 --num_workers 16 \
                   --processed-output %(results_dir)s/%(name)s.processed \
                   --lowqual-output %(results_dir)s/%(name)s.lowqual.fastq.gz \
                   --bin-output %(results_dir)s/%(name)s.binned_fastq.gz \
                   --stats-output %(results_dir)s/%(name)s.stats.csv \
                   -res %(results_dir)s -i %(infile)s -v --indexes "%(INDEXES)s"'''
    P.run(statement)

@follows(separate_by_index)
@follows(mkdir("merged_results.dir"))
@originate("merged_results.dir/merge_complete")
def merge_by_index(outfile):
    '''
    Merge binned, lowqual, and processed fastq files from separate_samples.dir.
    '''
    statement = '''bash %(BASH_ROOT)s/cat_files_by_index.sh --indexes "%(INDEXES)s"'''
    P.run(statement)

@follows(merge_by_index)
@originate("merged_results.dir/merged_stats.csv")
def merge_stats(outfile):
    '''
    Merge stats from all separate_samples.dir into a single CSV file.
    '''
    original_input = glob.glob("data.dir/*.fastq.gz")[0]  # Get the original input filename
    name_stem = os.path.basename(original_input).replace('.fastq.gz', '')
    statement = '''python %(PYTHON_ROOT)s/merge_index_stats.py --input-dir separate_samples.dir --output-file merged_results.dir/%(name_stem)s.merged_stats.csv'''
    P.run(statement)

@follows(merge_stats)
def full():
    pass

def main(argv=None):
    if argv is None:
        argv = sys.argv
    P.main(argv)

if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
